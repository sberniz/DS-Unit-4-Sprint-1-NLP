{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S1-NLP-DS11",
      "language": "python",
      "name": "u4-s1-nlp-ds11"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Copy of LS_DS_413_Document_Classification_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sberniz/DS-Unit-4-Sprint-1-NLP/blob/main/module3-document-classification/LS_DS_413_Document_Classification_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UImOLsUJn2R7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "a8ea66b2-6d2a-40bf-f787-eb2d0fa9fbb8"
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (49.6.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIiNpRmek050",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 1, Module 3*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1z3vgIIk055",
        "colab_type": "text"
      },
      "source": [
        "# Document Classification (Assignment)\n",
        "\n",
        "This notebook is for you to practice skills during lecture.\n",
        "\n",
        "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
        "\n",
        "Today's all about having fun and practicing your skills.\n",
        "\n",
        "## Sections\n",
        "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
        "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
        "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
        "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqZ7j2VDk056",
        "colab_type": "text"
      },
      "source": [
        "# Text Feature Extraction & Classification Pipelines (Learn)\n",
        "<a id=\"p1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "vXTjhzGJk057",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along \n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model (try using the pipe method I just demoed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH7-gscQk058",
        "colab_type": "text"
      },
      "source": [
        "### Load Competition Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-cP1SSzk059",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# You may need to change the path\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3qXp_mpq6Lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Statements\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saaUbOvck06H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "1464d8e7-409c-4d30-c875-eb9d2e97f6b0"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>description</th>\n",
              "      <th>ratingCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1321</td>\n",
              "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3861</td>\n",
              "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>655</td>\n",
              "      <td>\\nThis release is a port version of Amrutâ€™s In...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>555</td>\n",
              "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1965</td>\n",
              "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id                                        description  ratingCategory\n",
              "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
              "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
              "2   655  \\nThis release is a port version of Amrutâ€™s In...               1\n",
              "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
              "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjwHvUoVpAql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = train['ratingCategory']\n",
        "data = train.drop(columns=['id','ratingCategory'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-8V9-p-plP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "b2d96622-28cd-45da-e1b6-fee6b734f388"
      },
      "source": [
        "data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nThis release is a port version of Amrutâ€™s In...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4082</th>\n",
              "      <td>\\nWhat lies beneath the surface of Dewarâ€™s? He...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4083</th>\n",
              "      <td>\\nAfter 6 to 7 years of maturation in bourbon ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4084</th>\n",
              "      <td>\\nBright, delicate, and approachable. While no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4085</th>\n",
              "      <td>\\nIâ€™m calling this the pitmasterâ€™s dram: the n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4086</th>\n",
              "      <td>\\nSpicy sultanas, greengage plums, toffee, and...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4087 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            description\n",
              "0     \\nSometimes, when whisky is batched, a few lef...\n",
              "1     \\nAn uncommon exclusive bottling of a 6 year o...\n",
              "2     \\nThis release is a port version of Amrutâ€™s In...\n",
              "3     \\nThis 41 year old single cask was aged in a s...\n",
              "4     \\nQuite herbal on the nose, with aromas of dri...\n",
              "...                                                 ...\n",
              "4082  \\nWhat lies beneath the surface of Dewarâ€™s? He...\n",
              "4083  \\nAfter 6 to 7 years of maturation in bourbon ...\n",
              "4084  \\nBright, delicate, and approachable. While no...\n",
              "4085  \\nIâ€™m calling this the pitmasterâ€™s dram: the n...\n",
              "4086  \\nSpicy sultanas, greengage plums, toffee, and...\n",
              "\n",
              "[4087 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2SqFY8KqAzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "94d300d7-e781-4976-c603-d560b59bf89d"
      },
      "source": [
        "target"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       0\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "4082    1\n",
              "4083    1\n",
              "4084    1\n",
              "4085    1\n",
              "4086    1\n",
              "Name: ratingCategory, Length: 4087, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEf45fnxk06N",
        "colab_type": "text"
      },
      "source": [
        "### Define Pipeline Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J023DloGk06N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "pipe = Pipeline([('vect', vect), ('clf', clf)])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmhq0PcPk06T",
        "colab_type": "text"
      },
      "source": [
        "### Define Your Search Space\n",
        "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18NoPiPrk06e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "outputId": "9a78aa96-b672-4b43-ed76-6de488c8cf99"
      },
      "source": [
        "parameters = {\n",
        "    'vect__max_df': ( 0.75, 1.0),\n",
        "    'vect__min_df': (.02, .05),\n",
        "    'clf__max_depth':(5,10)\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(train['description'],train['ratingCategory'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   40.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vect',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 2),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words='english',\n",
              "                                                        strip...\n",
              "                                                               min_samples_split=2,\n",
              "                                                               min_weight_fraction_leaf=0.0,\n",
              "                                                               n_estimators=100,\n",
              "                                                               n_jobs=None,\n",
              "                                                               oob_score=False,\n",
              "                                                               random_state=None,\n",
              "                                                               verbose=0,\n",
              "                                                               warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__max_depth': (5, 10), 'vect__max_df': (0.75, 1.0),\n",
              "                         'vect__min_df': (0.02, 0.05)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flCm_-Nwu3XV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5955adc4-40f4-47a7-d24b-10632acd4f9c"
      },
      "source": [
        "grid_search.best_score_"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7134821473995445"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS4CTjEGu5X-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "00cf1bc7-4814-453c-d5e2-74981d5fe2ab"
      },
      "source": [
        "grid_search.predict(['wiskey i love it ', 'you won the lottery in Nigeria'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW3ik2rSk06x",
        "colab_type": "text"
      },
      "source": [
        "### Make a Submission File\n",
        "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tb9AlSvk06z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predictions on test sample\n",
        "pred = grid_search.predict(test['description'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbAxMFY4k07D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
        "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-RVdzDhk07S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b87927e1-f4b6-4648-f19a-6a964a057ca1"
      },
      "source": [
        "# Make Sure the Category is an Integer\n",
        "submission.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ratingCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3461</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2604</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3341</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3764</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2306</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ratingCategory\n",
              "0  3461               1\n",
              "1  2604               1\n",
              "2  3341               1\n",
              "3  3764               1\n",
              "4  2306               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI2sGIjck07j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subNumber = 0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_apCd_7ck07n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save your Submission File\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\n",
        "\n",
        "submission.to_csv(f'submission{subNumber}.csv', index=False)\n",
        "subNumber += 1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SXssTWWk07y",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You're trying to achieve a minimum of 70% Accuracy on your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S54Q-VgTk07y",
        "colab_type": "text"
      },
      "source": [
        "## Latent Semantic Indexing (Learn)\n",
        "<a id=\"p2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "gh4P71DPk07z",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
        "4. Make a submission to Kaggle \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaZ4f0zYk071",
        "colab_type": "text"
      },
      "source": [
        "### Define Pipeline Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5kEUNFHyLse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpyoqlfsyPn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svd = TruncatedSVD(n_components=100,\n",
        "                   algorithm='randomized',\n",
        "                   n_iter=5)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q7QDYZCk07_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
        "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
        "clf = RandomForestClassifier(n_jobs=-1,random_state=42)\n",
        "\n",
        "pipe = Pipeline([('lsi', lsi), ('clf', clf)])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2lzYi5Wyc1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "dac6e0d4-f5b3-4f54-c511-0ba57fd0ba0e"
      },
      "source": [
        "print(pipe)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pipeline(memory=None,\n",
            "         steps=[('lsi',\n",
            "                 Pipeline(memory=None,\n",
            "                          steps=[('vect',\n",
            "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
            "                                                  decode_error='strict',\n",
            "                                                  dtype=<class 'numpy.float64'>,\n",
            "                                                  encoding='utf-8',\n",
            "                                                  input='content',\n",
            "                                                  lowercase=True, max_df=1.0,\n",
            "                                                  max_features=None, min_df=1,\n",
            "                                                  ngram_range=(1, 2), norm='l2',\n",
            "                                                  preprocessor=None,\n",
            "                                                  smooth_idf=True,\n",
            "                                                  stop_words='english',\n",
            "                                                  strip_accents=...\n",
            "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
            "                                        class_weight=None, criterion='gini',\n",
            "                                        max_depth=None, max_features='auto',\n",
            "                                        max_leaf_nodes=None, max_samples=None,\n",
            "                                        min_impurity_decrease=0.0,\n",
            "                                        min_impurity_split=None,\n",
            "                                        min_samples_leaf=1, min_samples_split=2,\n",
            "                                        min_weight_fraction_leaf=0.0,\n",
            "                                        n_estimators=100, n_jobs=-1,\n",
            "                                        oob_score=False, random_state=42,\n",
            "                                        verbose=0, warm_start=False))],\n",
            "         verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lxtgGoxk08D",
        "colab_type": "text"
      },
      "source": [
        "### Define Your Search Space\n",
        "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpzsnR8Uk08E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "3eb6e5ad-23ae-436d-e590-a9b9accbacc9"
      },
      "source": [
        "parameters = {\n",
        "    'lsi__svd__n_components': [10,100,250],\n",
        "    'lsi__vect__max_df': (0.75, 1.0),\n",
        "    'clf__max_depth':(5,10,15,20)\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipe,parameters, cv=7,n_jobs=-1, verbose=10)\n",
        "grid_search.fit(data['description'], target)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 7 folds for each of 24 candidates, totalling 168 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   16.0s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   22.3s\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  6.8min\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  9.7min\n",
            "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 10.6min\n",
            "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed: 12.2min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 15.4min\n",
            "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed: 16.6min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 19.1min\n",
            "[Parallel(n_jobs=-1)]: Done 168 out of 168 | elapsed: 21.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=7, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('lsi',\n",
              "                                        Pipeline(memory=None,\n",
              "                                                 steps=[('vect',\n",
              "                                                         TfidfVectorizer(analyzer='word',\n",
              "                                                                         binary=False,\n",
              "                                                                         decode_error='strict',\n",
              "                                                                         dtype=<class 'numpy.float64'>,\n",
              "                                                                         encoding='utf-8',\n",
              "                                                                         input='content',\n",
              "                                                                         lowercase=True,\n",
              "                                                                         max_df=1.0,\n",
              "                                                                         max_features=None,\n",
              "                                                                         min_df=1,\n",
              "                                                                         ngram_range=(1,\n",
              "                                                                                      2),\n",
              "                                                                         norm='l2',\n",
              "                                                                         preprocessor=None,\n",
              "                                                                         smooth_...\n",
              "                                                               min_weight_fraction_leaf=0.0,\n",
              "                                                               n_estimators=100,\n",
              "                                                               n_jobs=-1,\n",
              "                                                               oob_score=False,\n",
              "                                                               random_state=42,\n",
              "                                                               verbose=0,\n",
              "                                                               warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__max_depth': (5, 10, 15, 20),\n",
              "                         'lsi__svd__n_components': [10, 100, 250],\n",
              "                         'lsi__vect__max_df': (0.75, 1.0)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM_9ysFT1Bxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "23a2688e-06d3-4df6-d7ed-35e39deb48ff"
      },
      "source": [
        "grid_search.best_score_"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.723515757956182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OkIzd6U1FnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi0H7gwbk08H",
        "colab_type": "text"
      },
      "source": [
        "### Make a Submission File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8YUzNO4k08I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predictions on test sample\n",
        "pred = grid_search.predict(test['description'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc7bYufsk08Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
        "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMYTujElk08U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "5488143b-da4d-44b1-a8f4-f98f5f354931"
      },
      "source": [
        "# Make Sure the Category is an Integer\n",
        "submission.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ratingCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3461</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2604</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3341</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3764</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2306</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ratingCategory\n",
              "0  3461               1\n",
              "1  2604               1\n",
              "2  3341               1\n",
              "3  3764               1\n",
              "4  2306               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP2sUx8Sk08X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save your Submission File\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\n",
        "\n",
        "submission.to_csv(f'submission{subNumber}.csv', index=False)\n",
        "subNumber += 1"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtGdXKCQk08h",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRJZyh-Fk08i",
        "colab_type": "text"
      },
      "source": [
        "# Word Embeddings with Spacy (Learn)\n",
        "<a id=\"p3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVN1iDShk08j",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thMRRn2Lk08k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply to your Dataset\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_dist = {\n",
        "    \n",
        "    'max_depth' : randint(3,10),\n",
        "    'min_samples_leaf': randint(2,15)\n",
        "}"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh01UDK-k08p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Continue Word Embedding Work Here\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ3aTwp_Ucj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word_vectors(docs):\n",
        "    return [nlp(doc).vector for doc in docs]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQTvlqz3Uh3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4997b509-4112-46ca-8ba1-ef4ff563eb02"
      },
      "source": [
        "X = get_word_vectors(data['description'])\n",
        "len(X) == len(data['description'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTs8YmKKU5ZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf1 = RandomForestClassifier()\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upIPcqzHVRHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "52d5e990-7c85-4900-f1f2-aa6e1b3e8432"
      },
      "source": [
        "clf1.fit(X,target)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeW7qOAqVZBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b295d41f-8213-49b9-aff9-65269faf6c96"
      },
      "source": [
        "clf1.score(X,target)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT44HfoFXWVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6McIcjCf2pP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh2U4UBaYBE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf2 = XGBClassifier(random_state=42)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qotrn8UwbSlR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7570dee0-43ca-42ec-c913-3325901d0ea2"
      },
      "source": [
        "clf2.fit(np.array(X),target)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=42,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpPByLW8gKbN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c340eff1-9e4d-4e30-ae50-cd851dd54439"
      },
      "source": [
        ""
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.857841937851725"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gBPz72XY3aM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_dist = {\n",
        "    \n",
        "    'max_depth' :[5,10,20],\n",
        "    'n_estimators':[100,110,120,150,200]\n",
        "}"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9-obdnoZqfI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "b9b2dd65-ecc1-4fc2-c395-b1bf93187144"
      },
      "source": [
        "grid_search2 = GridSearchCV(clf2,param_dist,cv=5,n_jobs=-1,verbose=10)\n",
        "grid_search2.fit(np.array(X),target)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   50.5s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  6.4min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 11.3min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 16.1min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 23.5min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 31.7min\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed: 42.5min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 53.6min\n",
            "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed: 62.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                     colsample_bylevel=1, colsample_bynode=1,\n",
              "                                     colsample_bytree=1, gamma=0,\n",
              "                                     learning_rate=0.1, max_delta_step=0,\n",
              "                                     max_depth=3, min_child_weight=1,\n",
              "                                     missing=None, n_estimators=100, n_jobs=1,\n",
              "                                     nthread=None, objective='multi:softprob',\n",
              "                                     random_state=42, reg_alpha=0, reg_lambda=1,\n",
              "                                     scale_pos_weight=1, seed=None, silent=None,\n",
              "                                     subsample=1, verbosity=1),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'max_depth': [5, 10, 20],\n",
              "                         'n_estimators': [100, 110, 120, 150, 200]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViaL18QHfTqs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd1bd126-e798-4fdf-f21e-363907da268d"
      },
      "source": [
        "grid_search2.best_params_"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 5, 'n_estimators': 120}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLvZ8eaVfbn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d08482f4-afdc-432a-d27d-bbd987d42cb3"
      },
      "source": [
        "grid_search2.best_score_"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7430871487013434"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k8rNws8xyMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ypred4 = grid_search2.predict(X_test)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_ymgBMSyW6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmJ8tyzUyatQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf3 = DecisionTreeClassifier()"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKDkuV0LydbO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "47a011f2-c1b0-44bf-a065-b2bfec041b93"
      },
      "source": [
        "clf3.fit(X,target)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKXbS-HMyhBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6edc059f-9dce-4dbf-cca2-439097db17b4"
      },
      "source": [
        "clf3.score(X,target)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k27wQAfJylKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ypred5 = clf3.predict(X_test)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umm2hggEk08u",
        "colab_type": "text"
      },
      "source": [
        "### Make a Submission File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SVeQj6kk08u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predictions on test sample\n",
        "X_test = get_word_vectors(test['description'])\n",
        "pred = clf1.predict(X_test)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhK7FO7jWepq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ypred2 = grid_search2.predict(X_test)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H05hpa1ggXDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ypred3 = clf2.predict(X_test)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fXJcXWSgbUT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6a44ea9-6acc-4a83-f3ae-f84485cb2e3d"
      },
      "source": [
        "ypred3"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_zrtlh0k08x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':ypred5})\n",
        "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMZZbGzqk080",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "cdf8cbb1-0cc6-46b2-975d-87936dac8c02"
      },
      "source": [
        "# Make Sure the Category is an Integer\n",
        "submission.head()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ratingCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3461</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2604</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3341</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3764</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2306</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ratingCategory\n",
              "0  3461               1\n",
              "1  2604               1\n",
              "2  3341               1\n",
              "3  3764               1\n",
              "4  2306               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnCXnG2jgo-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNtH_b8fgvE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8604e5a7-b8c0-4461-b3b8-fb8b0c9d2e2b"
      },
      "source": [
        "ypredt = clf2.predict(X)\n",
        "accuracy_score(target,ypredt)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.857841937851725"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lATd8Ibk083",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save your Submission File\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\n",
        "\n",
        "submission.to_csv(f'submission{subNumber}.csv', index=False)\n",
        "subNumber += 1"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YodSaiUWk09B",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
        "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
        "4. Make a submission to Kaggle "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeE1GTG5k09B",
        "colab_type": "text"
      },
      "source": [
        "# Post Lecture Assignment\n",
        "<a id=\"p4\"></a>\n",
        "\n",
        "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
        "\n",
        "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
        "    - What is \"Sentiment Analysis\"? \n",
        "\n",
        "    ```Sentiment analysis (also known as opinion mining or emotion AI) refers to the use of natural language processing, use of data science to systematically identify, extract, quantify, and study affective states and subjective information. for example detect the of the person writing a statemnet. such as happy/sad,angry, etc.  ```\n",
        "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
        "    ```Yes, Document Clasification can be used to classified a document(Text data) into different categories, such as technology, physics, etc. and while it can also classify a sentiment.. a sentiment analysis just analyses the sentiment or emotion of the sentence. ```\n",
        "    - How do create labeled sentiment data? Are those labels really sentiment? \n",
        "    ```We need define clear rules, for example is profanity is labled as negative, we should keep consistent and test randomness,the labels are not really sentiments ```\n",
        "    - What are common applications of sentiment analysis?\n",
        "    ```Nowadays probably most common application is for targeted marketing, which analyses person state from for example reviews, to market certain products```\n",
        "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
        "```In my case it workedthe same on both on the training data. however,one reason is because the sentiment was different```\n",
        "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
        "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
      ]
    }
  ]
}